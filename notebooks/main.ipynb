{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Heartbeat Arrhythmia Detection with Convolutional Neural Networks at MIT-BIH dataset\n",
    "---\n",
    "##### Part 1.1\n",
    "---\n",
    "###### * Downloading dataset\n",
    "###### * File manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Importing built-in libraries for file/path manipulation\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Importing WFDB library for getting data from PhysioNet and reading files\n",
    "from wfdb.io import get_dbs\n",
    "from wfdb.io import dl_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Change current working directory\n",
    "print(\"Directory before changing it: \" + os.getcwd())\n",
    "os.chdir(\"..\")\n",
    "print(\"Directory after changing it: \" + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Download data if it's not exist in data directory,\n",
    "# otherwise download it from PhysioNet\n",
    "\n",
    "if not os.path.exists(\"data/mitdb\"):\n",
    "    dbs = get_dbs()\n",
    "    print(dbs)\n",
    "\n",
    "    subs = 'MIT-BIH'\n",
    "    res = [[index, sub_string] for index, sub_string in enumerate(dbs) if subs in sub_string[1]]\n",
    "    print(res)\n",
    "    os.mkdir(\"data/mitdb\")\n",
    "    dl_database('mitdb', dl_dir='data/mitdb')\n",
    "else:\n",
    "    print(\"Data directory exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_file_paths():\n",
    "    # Getting paths for records and annotations\n",
    "    record_paths = glob.glob(\"data/mitdb/*.dat\")\n",
    "    annot_paths = glob.glob(\"data/mitdb/*.atr\")\n",
    "    hea_paths = glob.glob(\"data/mitdb/*.hea\")\n",
    "\n",
    "    # Sort lists\n",
    "    record_paths.sort()\n",
    "    annot_paths.sort()\n",
    "    hea_paths.sort()\n",
    "    # Create path dict\n",
    "    p = {\"rec_path\": record_paths,\n",
    "         \"ann_path\": annot_paths,\n",
    "         \"hea_path\": hea_paths}\n",
    "\n",
    "    return p\n",
    "\n",
    "paths = get_file_paths()\n",
    "# Throws error if total data file number is not equeal to other specs\n",
    "try:\n",
    "    if len(paths[\"rec_path\"]) != len(paths[\"ann_path\"]) != len(paths[\"hea_path\"]):\n",
    "        raise IOError\n",
    "\n",
    "except IOError:\n",
    "    print(\"Some data files are missing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Importing WFDB plot functions, uses Matplotlib\n",
    "from wfdb.io import rdann, rdrecord\n",
    "from wfdb.plot import plot_wfdb\n",
    "\n",
    "# Read 2 channel record and it's annotation\n",
    "record = rdrecord(paths[\"rec_path\"][0].split(\".\")[0], sampto=3000)\n",
    "ann = rdann(paths[\"ann_path\"][0].split(\".\")[0], \"atr\", sampto=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot graph with grids\n",
    "plot_wfdb(record=record, annotation=ann, plot_sym=True,\n",
    "          time_units='seconds',\n",
    "          figsize=(12, 5), ecg_grids='all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "##### Part 1.2\n",
    "---\n",
    "###### * Ploting raw data (Bar plot, pie chart etc.)\n",
    "###### * Data analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Import beat dictionary\n",
    "from data import beat_ann\n",
    "\n",
    "def get_beat_count_dict():\n",
    "    # Create empty dictionary to hold all count values\n",
    "    bc_dict = {}\n",
    "    # Take all patients in annotation lists\n",
    "    for patient in range(len(paths[\"ann_path\"])):\n",
    "        annot = rdann(paths[\"ann_path\"][patient].split(\".\")[0], \"atr\")\n",
    "        # Take all beats\n",
    "        for beat_type in annot.symbol:\n",
    "            # Check if beat type is in pre-defined beat dictionary\n",
    "            if beat_type in beat_ann:\n",
    "                # If dictionary does not include that beat type create a key-value pair and assign to 1\n",
    "                if beat_type not in bc_dict.keys():\n",
    "                    bc_dict[beat_type] = 1\n",
    "                # Otherwise add 1 to value of matched beat type\n",
    "                else:\n",
    "                    bc_dict[beat_type] += 1\n",
    "\n",
    "    return bc_dict\n",
    "\n",
    "beat_count_dict = get_beat_count_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Importing NumPy\n",
    "import numpy as np\n",
    "from data import b_to_sb\n",
    "\n",
    "def get_sb_list():\n",
    "    sbl = []\n",
    "    count_labels, count_values = np.array(list(beat_count_dict.items())).T\n",
    "\n",
    "    for beat_type in list(b_to_sb.keys()):\n",
    "        sbl.append([beat_type,\n",
    "                    count_values[list(count_labels).index(beat_type)],\n",
    "                    b_to_sb[beat_type]])\n",
    "\n",
    "    # List contains beat types, beat counts and super beat classes according to its order\n",
    "    sbl = np.array(sbl)\n",
    "    return sbl\n",
    "\n",
    "sb_list = get_sb_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Importing Seaborn and Matplotlib.PyPlot to plot graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Importing Matplotlib.Patches to create custom legends\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Importing only super class names\n",
    "from data import sb_ann_palette, sb_ann_class, sb_ann_class_palette, sb_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Creating bar plot figure with specified size\n",
    "def draw_barplot_sb_class():\n",
    "    fig, (norm_ax, log_ax) = plt.subplots(2, figsize=(15, 10))\n",
    "    # Defining legend patches for superior arrythmia classes\n",
    "    patch_list = [mpatches.Patch(color=p, label=l + \": \" + sb_ann[l]) for p, l in zip(sb_ann_class_palette, sb_ann_class)]\n",
    "\n",
    "    sns.barplot(sb_list[:, 0], sb_list[:, 1], palette=sb_ann_palette, ax=norm_ax)\n",
    "    # Setting y-axis to normal scale and adding horizontal grid\n",
    "    norm_ax.grid(True, axis=\"y\", which=\"major\", ls=\"-.\")\n",
    "    norm_ax.set_title(\"Normal Scale\")\n",
    "    # Implementing custom legend\n",
    "    _ = norm_ax.legend(handles=patch_list)\n",
    "    # Show the plot\n",
    "\n",
    "    # Ploting bar plot with seaborn\n",
    "    sns.barplot(sb_list[:, 0], sb_list[:, 1], palette=sb_ann_palette, ax=log_ax)\n",
    "    # Setting y-axis to logarithmic scale and adding horizontal grid\n",
    "    log_ax.set_yscale(\"log\")\n",
    "    log_ax.grid(True, axis=\"y\", which=\"major\", ls=\"-.\")\n",
    "    log_ax.set_title(\"Log Scale\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "draw_barplot_sb_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Printing beat names and counts\n",
    "def print_instance_counts():\n",
    "    print(\"Instance Count\\t|\\tAnnotation (Super Beat)\")\n",
    "    for i, c, s in np.array(sb_list[:,:]):\n",
    "        print(f\"{c}\\t\\t|\\t{i}: {beat_ann[i]} ({s})\")\n",
    "print_instance_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate total super beat instances\n",
    "def get_sb_instances():\n",
    "    sbeat_count_dict = {}\n",
    "    for sb in sb_ann_class:\n",
    "        cnt = 0\n",
    "        for c, b in np.array(sb_list)[:, 1:]:\n",
    "            if sb == b:\n",
    "                cnt += int(c)\n",
    "        sbeat_count_dict[sb] = cnt\n",
    "\n",
    "    return sbeat_count_dict\n",
    "\n",
    "sb_count_dict = get_sb_instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Creating pie chart figure with specified size\n",
    "def draw_pie_chart_sb_class():\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    # Total super beat class instances\n",
    "    total = sum(list(sb_count_dict.values()))\n",
    "    # Divide all super beat class instances to total beat number to define pie chart percentage row values\n",
    "    sizes = [(size / total) * 100 for size in list(sb_count_dict.values())]\n",
    "    # Set pie chart class parts explode\n",
    "    explode = (0.1, 0.3, 0.2, 0.4, 0.2)\n",
    "    # Draw pie chart\n",
    "    plt.pie(sizes, explode=explode, labels=list(sb_ann.values()), autopct='%1.1f%%',\n",
    "            pctdistance=0.7, textprops={\"fontsize\": \"x-large\"}, colors=sb_ann_class_palette,\n",
    "            shadow=False, startangle=0)\n",
    "    # Setting all axis to equal to get perfect circular pie chart\n",
    "    plt.axis('equal')\n",
    "    # Define row values of table plot\n",
    "    rows = [[str(integer) for integer in list(sb_count_dict.values())]]\n",
    "    row_label = [\"Instances\"]\n",
    "    # Defining column headers of table plot\n",
    "    cols = tuple(sb_count_dict.keys())\n",
    "    # Draw table\n",
    "    table = plt.table(cellText=rows,\n",
    "                      colLabels=cols,\n",
    "                      rowLabels=row_label,\n",
    "                      loc=\"bottom\",\n",
    "                      cellLoc=\"center\",\n",
    "                      rowLoc=\"center\",\n",
    "                      colLoc=\"center\")\n",
    "    # Scale table and font size\n",
    "    table.scale(1, 2.5)\n",
    "    table.set_fontsize(20)\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "draw_pie_chart_sb_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "##### Part 1.3\n",
    "---\n",
    "###### * Find optimized beat width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Take random beat and compare different beat widths\n",
    "def plot_beat_comparison(beat_list):\n",
    "    fig, axes = plt.subplots(nrows=len(beat_list), ncols=1, figsize=(15, 25))\n",
    "    fig.tight_layout(pad=2.0)\n",
    "\n",
    "    for ax, width in zip(axes, beat_list):\n",
    "        ax.plot(record.p_signal[ann.sample[8] - width // 2:\n",
    "                                ann.sample[8] + width // 2, 0], \"r\",\n",
    "                record.p_signal[ann.sample[8] - width // 2:\n",
    "                                ann.sample[8] + width // 2, 1], \"b\")\n",
    "        ax.set_title(f\"Beat width: {width}\")\n",
    "        ax.grid(True)\n",
    "    axes[0].legend(record.sig_name)\n",
    "    plt.show(fig)\n",
    "\n",
    "beat_width_list = [30, 40, 50, 100, 120, 150]\n",
    "plot_beat_comparison(beat_width_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Plotting ideal beat width\n",
    "def plot_ideal_beat_width(beat_list):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(record.p_signal[ann.sample[8] - beat_list[0]:\n",
    "                             ann.sample[8] + beat_list[1], 0], \"r\",\n",
    "             record.p_signal[ann.sample[8] - beat_list[0]:\n",
    "                             ann.sample[8] + beat_list[1], 1], \"b\",\n",
    "             figure=fig)\n",
    "\n",
    "    plt.title(\"Ideal Beat Width\")\n",
    "    plt.legend(record.sig_name)\n",
    "    plt.grid(True)\n",
    "    plt.show(fig)\n",
    "\n",
    "# 150 sample before and 180 sample after from center point of the beat\n",
    "beat_width = [150, 180]\n",
    "plot_ideal_beat_width(beat_width)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "##### Part 1.4\n",
    "---\n",
    "###### * Data split into train and test\n",
    "###### * Distribution analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_test_split(train_ratio=0.7):\n",
    "    x = []\n",
    "    y = []\n",
    "    n_count = 0\n",
    "    for rec_path, ann_path in zip(paths[\"rec_path\"], paths[\"ann_path\"]):\n",
    "        rec = rdrecord(rec_path.split(\".\")[0])\n",
    "        an = rdann(ann_path.split(\".\")[0], \"atr\")\n",
    "        for beat, symbol in zip(an.sample[2:-2], an.symbol[2: -2]):\n",
    "            if symbol in list(beat_count_dict.keys()):\n",
    "                if symbol is \"N\" and n_count < 10000:\n",
    "                    n_count += 1\n",
    "                    x.append([rec.p_signal[beat - beat_width[0]: beat + beat_width[1]]])\n",
    "                    y.append(b_to_sb[symbol])\n",
    "                elif symbol is not \"N\":\n",
    "                    x.append([rec.p_signal[beat - beat_width[0]: beat + beat_width[1]]])\n",
    "                    y.append(b_to_sb[symbol])\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(x)\n",
    "    random.seed(0)\n",
    "    random.shuffle(y)\n",
    "\n",
    "    x_tr, x_te = x[: int(len(x) * train_ratio)], x[int(len(x) * train_ratio):]\n",
    "    y_tr, y_te = y[: int(len(y) * train_ratio)], y[int(len(y) * train_ratio):]\n",
    "\n",
    "    return np.array(x_tr).squeeze(), np.array(x_te).squeeze(), \\\n",
    "           np.array(y_tr).squeeze(), np.array(y_te).squeeze()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_train_test_count():\n",
    "    tr_list = [[i, list(y_train).count(i)] for i in set(list(y_train))]\n",
    "    te_list = [[k, list(y_test).count(k)] for k in set(list(y_test))]\n",
    "    te_list.sort(key = lambda i: sb_ann_class.index(i[0]))\n",
    "    tr_list.sort(key = lambda i: sb_ann_class.index(i[0]))\n",
    "    return np.array(tr_list), np.array(te_list)\n",
    "\n",
    "train_list, test_list = get_train_test_count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating bar plot figure with specified size\n",
    "def draw_barplot_train_test():\n",
    "    fig, (train_ax, test_ax) = plt.subplots(2, figsize=(15, 10))\n",
    "    # Defining legend patches for superior arrythmia classes\n",
    "    patch_list = [mpatches.Patch(color=p, label=l + \": \" + sb_ann[l]) for p, l in zip(sb_ann_class_palette, sb_ann_class)]\n",
    "\n",
    "    sns.barplot(train_list[:, 0], train_list[:, 1], palette=sb_ann_class_palette, ax=train_ax)\n",
    "    # Setting y-axis to normal scale and adding horizontal grid\n",
    "    train_ax.grid(True, axis=\"y\", which=\"major\", ls=\"-.\")\n",
    "    train_ax.set_title(\"Train Distribution\")\n",
    "    # Implementing custom legend\n",
    "    _ = train_ax.legend(handles=patch_list)\n",
    "    # Show the plot\n",
    "\n",
    "    # Ploting bar plot with seaborn\n",
    "    sns.barplot(test_list[:, 0], test_list[:, 1], palette=sb_ann_class_palette, ax=test_ax)\n",
    "    # Setting y-axis to normal scale and adding horizontal grid\n",
    "    test_ax.grid(True, axis=\"y\", which=\"major\", ls=\"-.\")\n",
    "    test_ax.set_title(\"Test Distribution\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "draw_barplot_train_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "##### Part 2.1\n",
    "---\n",
    "###### * Model creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pre-defined model parameters\n",
    "\n",
    "epoch = 20\n",
    "batch_size = 50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Importing signal libraries\n",
    "import scipy as sp\n",
    "# and deep learning frameworks to creating deep learning model for classification and recognition\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.layers import Conv1D, AvgPool1D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "inp = Input(shape=(330, 2), name=\"input\")\n",
    "\n",
    "conv1_1 = Conv1D(32, 11, activation=\"relu\", name=\"conv1_1\")(inp)\n",
    "conv1_2 = Conv1D(64, 11, activation=\"relu\", name=\"conv1_2\")(conv1_1)\n",
    "\n",
    "av_pool_1 = AvgPool1D(pool_size=2, strides=2, name=\"average_pool_1\")(conv1_2)\n",
    "\n",
    "conv1_3 = Conv1D(128, 9, activation=\"relu\", name=\"conv1_3\")(av_pool_1)\n",
    "conv1_5 = Conv1D(256, 9, activation=\"relu\", name=\"conv1_5\")(conv1_3)\n",
    "\n",
    "av_pool_2 = AvgPool1D(pool_size=2, strides=2, name=\"average_pool_2\")(conv1_5)\n",
    "\n",
    "conv1_6 = Conv1D(256, 7, activation=\"relu\", name=\"conv1_6\")(av_pool_2)\n",
    "conv1_7 = Conv1D(256, 7, activation=\"relu\", name=\"conv1_7\")(conv1_6)\n",
    "\n",
    "av_pool_3 = AvgPool1D(pool_size=2, strides=2, name=\"average_pool_3\")(conv1_7)\n",
    "\n",
    "conv1_8 = Conv1D(512, 5, activation=\"relu\", name=\"conv1_8\")(av_pool_3)\n",
    "conv1_9 = Conv1D(512, 5, activation=\"relu\", name=\"conv1_9\")(conv1_8)\n",
    "\n",
    "flat = Flatten(name=\"flatten\")(conv1_9)\n",
    "\n",
    "dense_1 = Dense(1024, activation=\"relu\", name=\"dense_1\")(flat)\n",
    "drop_1 = Dropout(0.2, name=\"dropout_1\")(dense_1)\n",
    "\n",
    "dense_2 = Dense(512, activation=\"relu\", name=\"dense_2\")(drop_1)\n",
    "drop_2 = Dropout(0.2, name=\"dropout_2\")(dense_2)\n",
    "\n",
    "dense_3 = Dense(256, activation=\"relu\", name=\"dense_3\")(drop_2)\n",
    "drop_3 = Dropout(0.2, name=\"dropout_3\")(dense_3)\n",
    "\n",
    "dense_4 = Dense(128, activation=\"relu\", name=\"dense_4\")(drop_3)\n",
    "drop_4 = Dropout(0.2, name=\"dropout_4\")(dense_4)\n",
    "\n",
    "dense_5 = Dense(64, activation=\"relu\", name=\"dense_5\")(drop_4)\n",
    "drop_5 = Dropout(0.2, name=\"dropout_5\")(dense_5)\n",
    "\n",
    "out = Dense(5, activation=\"softmax\", name=\"dense_6_out\")(drop_5)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out, name=\"arr-cnn\")\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-1fced39",
   "language": "python",
   "display_name": "PyCharm (arrhythmia-cnn)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}